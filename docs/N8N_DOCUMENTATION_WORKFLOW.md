# 🤖 ResearchHub Documentation Automation with n8n

## 📋 Complete n8n Workflow for Documentation Rebuild

This is a comprehensive n8n workflow that automates the documentation analysis, categorization, and migration process using AI and the Diátaxis framework.

### 🎯 Workflow Overview

```json
{
  "name": "ResearchHub Documentation Rebuild - Diátaxis Framework",
  "active": false,
  "nodes": [
    {
      "parameters": {},
      "id": "start-trigger",
      "name": "Start Documentation Analysis",
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [240, 300],
      "webhookId": "rebuild-docs"
    },
    {
      "parameters": {
        "operation": "read",
        "fileSelector": "d:/MAMP/AfakarM/**/*.md",
        "options": {
          "encoding": "utf8"
        }
      },
      "id": "scan-all-docs",
      "name": "Scan All Documentation Files",
      "type": "n8n-nodes-base.readWriteFile",
      "typeVersion": 1,
      "position": [460, 300]
    },
    {
      "parameters": {
        "language": "javaScript",
        "jsCode": "// Process and prepare documentation files for AI analysis\nconst processedFiles = [];\n\nfor (const item of items) {\n  const fileName = item.json.fileName || item.binary?.data?.fileName || 'unknown';\n  const content = item.json.data || item.binary?.data?.toString() || '';\n  const fileSize = content.length;\n  const lastModified = item.json.lastModified || new Date().toISOString();\n  \n  // Extract metadata from filename and path\n  const isInDocsFolder = fileName.includes('/docs/');\n  const isInRootFolder = !fileName.includes('/') || fileName.split('/').length <= 2;\n  const fileExtension = fileName.split('.').pop();\n  const baseName = fileName.split('/').pop().replace('.md', '');\n  \n  // Determine priority based on location and content\n  let priority = 'medium';\n  if (isInRootFolder && fileSize > 1000) priority = 'high';\n  if (isInDocsFolder && fileName.includes('requirements')) priority = 'critical';\n  if (fileSize < 200) priority = 'low';\n  \n  // Extract content preview (first 500 chars)\n  const contentPreview = content.substring(0, 500);\n  \n  processedFiles.push({\n    json: {\n      fileName,\n      content,\n      contentPreview,\n      fileSize,\n      lastModified,\n      isInDocsFolder,\n      isInRootFolder,\n      priority,\n      baseName,\n      needsAnalysis: true\n    }\n  });\n}\n\n// Sort by priority and size for processing\nprocessedFiles.sort((a, b) => {\n  const priorityOrder = { critical: 4, high: 3, medium: 2, low: 1 };\n  return priorityOrder[b.json.priority] - priorityOrder[a.json.priority];\n});\n\nreturn processedFiles;"
      },
      "id": "process-files",
      "name": "Process & Prepare Files",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [680, 300]
    },
    {
      "parameters": {
        "resource": "chat",
        "operation": "complete",
        "model": "gpt-4",
        "messages": {
          "values": [
            {
              "role": "system",
              "content": "You are a documentation expert specializing in the Diátaxis framework. Analyze each document and categorize it into one of four types:\n\n1. TUTORIAL (learning-oriented): Step-by-step guides for beginners\n2. HOW_TO (problem-oriented): Solutions to specific problems\n3. REFERENCE (information-oriented): Technical specifications, APIs, schemas\n4. EXPLANATION (understanding-oriented): Background concepts, architecture\n5. DUPLICATE: Redundant content that should be archived\n6. OUTDATED: Old information that needs updating or removal\n\nReturn ONLY valid JSON format."
            },
            {
              "role": "user",
              "content": "Analyze this documentation file:\n\nFile: {{ $json.fileName }}\nSize: {{ $json.fileSize }} bytes\nLocation: {{ $json.isInDocsFolder ? 'docs folder' : 'root folder' }}\nContent Preview: {{ $json.contentPreview }}\n\nReturn JSON: {\"category\": \"TUTORIAL|HOW_TO|REFERENCE|EXPLANATION|DUPLICATE|OUTDATED\", \"confidence\": 0.95, \"reason\": \"Explanation of categorization\", \"suggestedTitle\": \"Improved Title\", \"targetPath\": \"docs/category/subcategory/\", \"actionRequired\": \"none|merge|update|archive\"}"
            }
          ]
        },
        "options": {
          "temperature": 0.3,
          "maxTokens": 300
        }
      },
      "id": "ai-categorize",
      "name": "AI Content Categorization",
      "type": "n8n-nodes-base.openAi",
      "typeVersion": 1,
      "position": [900, 300]
    },
    {
      "parameters": {
        "language": "javaScript",
        "jsCode": "// Parse AI responses and structure migration data\nconst migrationPlan = [];\nconst errors = [];\n\nfor (const item of items) {\n  try {\n    // Parse AI response\n    let aiResponse;\n    try {\n      aiResponse = JSON.parse(item.json.text || item.json.response || '{}');\n    } catch (parseError) {\n      // Try to extract JSON from text\n      const text = item.json.text || item.json.response || '';\n      const jsonMatch = text.match(/\\{[^}]+\\}/);\n      if (jsonMatch) {\n        aiResponse = JSON.parse(jsonMatch[0]);\n      } else {\n        throw new Error('Could not parse AI response');\n      }\n    }\n    \n    const originalData = item.json;\n    const category = aiResponse.category || 'EXPLANATION';\n    const confidence = aiResponse.confidence || 0.5;\n    const reason = aiResponse.reason || 'Default categorization';\n    const suggestedTitle = aiResponse.suggestedTitle || originalData.baseName;\n    const targetPath = aiResponse.targetPath || 'docs/explanation/';\n    const actionRequired = aiResponse.actionRequired || 'none';\n    \n    // Determine target directory based on category\n    let targetDir;\n    switch (category) {\n      case 'TUTORIAL':\n        targetDir = 'docs/tutorials/';\n        break;\n      case 'HOW_TO':\n        targetDir = 'docs/how-to-guides/';\n        break;\n      case 'REFERENCE':\n        targetDir = 'docs/reference/';\n        break;\n      case 'EXPLANATION':\n        targetDir = 'docs/explanation/';\n        break;\n      case 'DUPLICATE':\n      case 'OUTDATED':\n        targetDir = 'docs/archive/old-docs/';\n        break;\n      default:\n        targetDir = 'docs/archive/uncategorized/';\n    }\n    \n    // Create migration plan entry\n    migrationPlan.push({\n      json: {\n        sourceFile: originalData.fileName,\n        targetDir,\n        targetFile: targetDir + suggestedTitle + '.md',\n        category,\n        confidence,\n        reason,\n        suggestedTitle,\n        actionRequired,\n        fileSize: originalData.fileSize,\n        priority: originalData.priority,\n        content: originalData.content,\n        migrationStatus: 'planned'\n      }\n    });\n    \n  } catch (error) {\n    errors.push({\n      json: {\n        fileName: item.json.fileName || 'unknown',\n        error: error.message,\n        status: 'failed'\n      }\n    });\n  }\n}\n\n// Return migration plan sorted by priority and confidence\nmigrationPlan.sort((a, b) => {\n  if (a.json.priority !== b.json.priority) {\n    const priorityOrder = { critical: 4, high: 3, medium: 2, low: 1 };\n    return priorityOrder[b.json.priority] - priorityOrder[a.json.priority];\n  }\n  return b.json.confidence - a.json.confidence;\n});\n\n// Add summary as first item\nconst summary = {\n  json: {\n    type: 'summary',\n    totalFiles: migrationPlan.length,\n    errors: errors.length,\n    categories: {\n      TUTORIAL: migrationPlan.filter(p => p.json.category === 'TUTORIAL').length,\n      HOW_TO: migrationPlan.filter(p => p.json.category === 'HOW_TO').length,\n      REFERENCE: migrationPlan.filter(p => p.json.category === 'REFERENCE').length,\n      EXPLANATION: migrationPlan.filter(p => p.json.category === 'EXPLANATION').length,\n      DUPLICATE: migrationPlan.filter(p => p.json.category === 'DUPLICATE').length,\n      OUTDATED: migrationPlan.filter(p => p.json.category === 'OUTDATED').length\n    },\n    timestamp: new Date().toISOString()\n  }\n};\n\nreturn [summary, ...migrationPlan, ...errors];"
      },
      "id": "structure-migration",
      "name": "Structure Migration Plan",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,\n      "position": [1120, 300]\n    },\n    {\n      "parameters": {\n        "conditions": {\n          "options": {\n            "caseSensitive": true,\n            "leftValue": "",\n            "typeValidation": "strict"\n          },\n          "conditions": [\n            {\n              "id": "summary-condition",\n              "leftValue": "={{ $json.type }}",\n              "rightValue": "summary",\n              "operator": {\n                "type": "string",\n                "operation": "equals"\n              }\n            }\n          ],\n          "combinator": "and"\n        }\n      },\n      "id": "split-summary",\n      "name": "Split Summary from Files",\n      "type": "n8n-nodes-base.if",\n      "typeVersion": 2,\n      "position": [1340, 300]\n    },\n    {\n      "parameters": {\n        "resource": "chat",\n        "operation": "complete",\n        "model": "gpt-4",\n        "messages": {\n          "values": [\n            {\n              "role": "system",\n              "content": "You are a technical documentation specialist. Create a comprehensive cleanup and migration report for the ResearchHub documentation restructuring project. The report should be professional, actionable, and include specific recommendations."\n            },\n            {\n              "role": "user",\n              "content": "Generate a professional documentation cleanup report based on this analysis:\\n\\nTotal Files Analyzed: {{ $json.totalFiles }}\\nErrors Encountered: {{ $json.errors }}\\nCategorization Breakdown:\\n- Tutorials: {{ $json.categories.TUTORIAL }}\\n- How-to Guides: {{ $json.categories.HOW_TO }}\\n- Reference: {{ $json.categories.REFERENCE }}\\n- Explanations: {{ $json.categories.EXPLANATION }}\\n- Duplicates: {{ $json.categories.DUPLICATE }}\\n- Outdated: {{ $json.categories.OUTDATED }}\\n\\nCreate a report including:\\n1. Executive Summary\\n2. Analysis Results\\n3. Diátaxis Framework Benefits\\n4. Migration Recommendations\\n5. Quality Improvements\\n6. Next Steps\\n7. Maintenance Guidelines\\n\\nFormat as professional markdown document."\n            }\n          ]\n        },\n        "options": {\n          "temperature": 0.5,\n          "maxTokens": 2000\n        }\n      },\n      "id": "generate-report",\n      "name": "Generate Cleanup Report",\n      "type": "n8n-nodes-base.openAi",\n      "typeVersion": 1,\n      "position": [1560, 200]\n    },\n    {\n      "parameters": {\n        "operation": "write",\n        "fileName": "d:/MAMP/AfakarM/docs/reports/DOCUMENTATION_CLEANUP_REPORT_{{ DateTime.now().toFormat('yyyy-MM-dd') }}.md",\n        "dataPropertyName": "text"\n      },\n      "id": "save-report",\n      "name": "Save Cleanup Report",\n      "type": "n8n-nodes-base.readWriteFile",\n      "typeVersion": 1,\n      "position": [1780, 200]\n    },\n    {\n      "parameters": {\n        "language": "javaScript",\n        "jsCode": "// Execute the actual file migration based on the plan\\nconst fs = require('fs');\\nconst path = require('path');\\n\\nconst migrationResults = [];\\nconst baseDir = 'd:/MAMP/AfakarM';\\n\\n// Filter out summary and error items\\nconst filesToMigrate = items.filter(item => \\n  item.json.sourceFile && \\n  item.json.targetFile && \\n  item.json.migrationStatus === 'planned'\\n);\\n\\nfor (const item of filesToMigrate) {\\n  try {\\n    const sourceFile = path.resolve(baseDir, item.json.sourceFile);\\n    const targetFile = path.resolve(baseDir, item.json.targetFile);\\n    const targetDir = path.dirname(targetFile);\\n    \\n    // Create target directory if it doesn't exist\\n    if (!fs.existsSync(targetDir)) {\\n      fs.mkdirSync(targetDir, { recursive: true });\\n    }\\n    \\n    // Copy file to new location (keeping original for safety)\\n    if (fs.existsSync(sourceFile)) {\\n      // Add metadata header to migrated file\\n      const originalContent = item.json.content || fs.readFileSync(sourceFile, 'utf8');\\n      const metadata = `---\\n# Migrated from: ${item.json.sourceFile}\\n# Category: ${item.json.category}\\n# Migration Date: ${new Date().toISOString()}\\n# Confidence: ${item.json.confidence}\\n# Reason: ${item.json.reason}\\n---\\n\\n`;\\n      \\n      const newContent = metadata + originalContent;\\n      fs.writeFileSync(targetFile, newContent, 'utf8');\\n      \\n      migrationResults.push({\\n        json: {\\n          sourceFile: item.json.sourceFile,\\n          targetFile: item.json.targetFile,\\n          category: item.json.category,\\n          status: 'migrated',\\n          timestamp: new Date().toISOString()\\n        }\\n      });\\n    } else {\\n      migrationResults.push({\\n        json: {\\n          sourceFile: item.json.sourceFile,\\n          error: 'Source file not found',\\n          status: 'failed'\\n        }\\n      });\\n    }\\n    \\n  } catch (error) {\\n    migrationResults.push({\\n      json: {\\n        sourceFile: item.json.sourceFile,\\n        error: error.message,\\n        status: 'failed'\\n      }\\n    });\\n  }\\n}\\n\\n// Create migration log\\nconst migrationLog = {\\n  json: {\\n    type: 'migration_log',\\n    totalProcessed: filesToMigrate.length,\\n    successful: migrationResults.filter(r => r.json.status === 'migrated').length,\\n    failed: migrationResults.filter(r => r.json.status === 'failed').length,\\n    timestamp: new Date().toISOString(),\\n    results: migrationResults\\n  }\\n};\\n\\nreturn [migrationLog, ...migrationResults];"\n      },\n      "id": "execute-migration",\n      "name": "Execute File Migration",\n      "type": "n8n-nodes-base.code",\n      "typeVersion": 2,\n      "position": [1560, 400]\n    },\n    {\n      "parameters": {\n        "operation": "write",\n        "fileName": "d:/MAMP/AfakarM/docs/archive/migration-logs/MIGRATION_LOG_{{ DateTime.now().toFormat('yyyy-MM-dd_HH-mm-ss') }}.json",\n        "dataPropertyName": "results"\n      },\n      "id": "save-migration-log",\n      "name": "Save Migration Log",\n      "type": "n8n-nodes-base.readWriteFile",\n      "typeVersion": 1,\n      "position": [1780, 400]\n    },\n    {\n      "parameters": {\n        "language": "javaScript",\n        "jsCode": "// Create updated README with new documentation structure\\nconst updatedReadme = `# 📚 ResearchHub Documentation - Restructured\\n\\n**Last Updated**: ${new Date().toISOString().split('T')[0]}\\n**Framework**: Diátaxis Documentation Framework\\n**Migration Completed**: ${new Date().toISOString()}\\n\\n## 🎯 Quick Access\\n\\n### 📖 For New Users (Tutorials)\\n- [🚀 Getting Started](./docs/tutorials/getting-started/README.md)\\n- [🧪 First Study Creation](./docs/tutorials/study-creation/first-study.md)\\n\\n### 🔧 For Problem Solving (How-to Guides)\\n- [💻 Installation & Setup](./docs/how-to-guides/installation/)\\n- [🐛 Troubleshooting](./docs/how-to-guides/troubleshooting/)\\n\\n### 📚 For Reference (Technical Docs)\\n- [🔗 API Documentation](./docs/reference/api/)\\n- [🗄️ Database Schema](./docs/reference/database-schema/)\\n\\n### 💡 For Understanding (Explanations)\\n- [🏗️ Architecture Overview](./docs/explanation/architecture/)\\n- [🎯 Design Decisions](./docs/explanation/design-decisions/)\\n\\n## 📋 Complete Documentation Index\\n\\n👉 **[Master Documentation Index](./docs/MASTER_DOCUMENTATION_INDEX.md)** - Complete organized documentation\\n\\n## 🔄 What Changed\\n\\n✅ **Organized Structure**: Documentation now follows the Diátaxis framework\\n✅ **Clear Categories**: Tutorials, How-to Guides, Reference, and Explanation\\n✅ **Better Navigation**: Easy to find information based on your needs\\n✅ **Comprehensive Requirements**: Complete technical specifications\\n✅ **Archive System**: Old documentation preserved in archive\\n\\n## 🚀 Quick Start\\n\\n### For New Users\\n1. Start with [Getting Started Tutorial](./docs/tutorials/getting-started/)\\n2. Create your first study\\n3. Explore AI features\\n\\n### For Developers\\n1. Check [Development Setup](./docs/how-to-guides/installation/)\\n2. Review [API Documentation](./docs/reference/api/)\\n3. Understand [Architecture](./docs/explanation/architecture/)\\n\\n### For Troubleshooting\\n1. Browse [Common Issues](./docs/how-to-guides/troubleshooting/)\\n2. Check [Performance Guide](./docs/how-to-guides/troubleshooting/performance.md)\\n3. Review [Configuration](./docs/reference/configuration/)\\n\\n---\\n\\n**Framework**: [Diátaxis Documentation](https://diataxis.fr/) | **Migration**: Automated with n8n + AI`;\\n\\nreturn [{\\n  json: {\\n    content: updatedReadme,\\n    fileName: 'README.md',\\n    type: 'readme_update'\\n  }\\n}];"\n      },\n      "id": "update-readme",\n      "name": "Update Main README",\n      "type": "n8n-nodes-base.code",\n      "typeVersion": 2,\n      "position": [1560, 600]\n    },\n    {\n      "parameters": {\n        "operation": "write",\n        "fileName": "d:/MAMP/AfakarM/README.md",\n        "dataPropertyName": "content"\n      },\n      "id": "save-readme",\n      "name": "Save Updated README",\n      "type": "n8n-nodes-base.readWriteFile",\n      "typeVersion": 1,\n      "position": [1780, 600]\n    }\n  ],\n  "connections": {\n    "Start Documentation Analysis": {\n      "main": [[\n        {\n          "node": "Scan All Documentation Files",\n          "type": "main",\n          "index": 0\n        }\n      ]]\n    },\n    "Scan All Documentation Files": {\n      "main": [[\n        {\n          "node": "Process & Prepare Files",\n          "type": "main",\n          "index": 0\n        }\n      ]]\n    },\n    "Process & Prepare Files": {\n      "main": [[\n        {\n          "node": "AI Content Categorization",\n          "type": "main",\n          "index": 0\n        }\n      ]]\n    },\n    "AI Content Categorization": {\n      "main": [[\n        {\n          "node": "Structure Migration Plan",\n          "type": "main",\n          "index": 0\n        }\n      ]]\n    },\n    "Structure Migration Plan": {\n      "main": [[\n        {\n          "node": "Split Summary from Files",\n          "type": "main",\n          "index": 0\n        }\n      ]]\n    },\n    "Split Summary from Files": {\n      "main": [\n        [\n          {\n            "node": "Generate Cleanup Report",\n            "type": "main",\n            "index": 0\n          }\n        ],\n        [\n          {\n            "node": "Execute File Migration",\n            "type": "main",\n            "index": 0\n          }\n        ]\n      ]\n    },\n    "Generate Cleanup Report": {\n      "main": [[\n        {\n          "node": "Save Cleanup Report",\n          "type": "main",\n          "index": 0\n        }\n      ]]\n    },\n    "Execute File Migration": {\n      "main": [[\n        {\n          "node": "Save Migration Log",\n          "type": "main",\n          "index": 0\n        },\n        {\n          "node": "Update Main README",\n          "type": "main",\n          "index": 0\n        }\n      ]]\n    },\n    "Update Main README": {\n      "main": [[\n        {\n          "node": "Save Updated README",\n          "type": "main",\n          "index": 0\n        }\n      ]]\n    }\n  },\n  "pinData": {},\n  "settings": {\n    "executionOrder": "v1"\n  },\n  "staticData": null,\n  "tags": [\n    {\n      "createdAt": "2025-08-19T10:00:00.000Z",\n      "updatedAt": "2025-08-19T10:00:00.000Z",\n      "id": "documentation",\n      "name": "Documentation"\n    },\n    {\n      "createdAt": "2025-08-19T10:00:00.000Z",\n      "updatedAt": "2025-08-19T10:00:00.000Z",\n      "id": "automation",\n      "name": "Automation"\n    },\n    {\n      "createdAt": "2025-08-19T10:00:00.000Z",\n      "updatedAt": "2025-08-19T10:00:00.000Z",\n      "id": "ai",\n      "name": "AI"\n    }\n  ],\n  "triggerCount": 0,\n  "updatedAt": "2025-08-19T10:00:00.000Z",\n  "versionId": "1"\n}\n```\n\n## 🛠️ Setup Instructions\n\n### Prerequisites\n1. **n8n Installation**: Cloud or self-hosted n8n instance\n2. **OpenAI API Key**: For AI-powered content analysis\n3. **File System Access**: n8n must have read/write access to your project directory\n\n### Configuration Steps\n\n1. **Import Workflow**:\n   - Copy the JSON workflow above\n   - Import into your n8n instance\n   - Save as \"ResearchHub Documentation Rebuild\"\n\n2. **Configure Credentials**:\n   - Add OpenAI API credentials\n   - Configure file system permissions\n\n3. **Update Paths**:\n   - Modify all file paths from `d:/MAMP/AfakarM/` to your project path\n   - Update the manual trigger webhook ID if needed\n\n4. **Test Configuration**:\n   - Run \"Test Workflow\" to validate setup\n   - Check file permissions and API connections\n\n### 🔧 Customization Options\n\n#### AI Prompts\nModify the OpenAI nodes to adjust categorization criteria:\n\n```javascript\n// Example: Custom categorization prompt\n\"You are a ResearchHub documentation expert. Categorize based on:\n- TUTORIAL: Step-by-step learning for new users\n- HOW_TO: Problem-solving guides for specific issues  \n- REFERENCE: Technical specs, API docs, database schemas\n- EXPLANATION: Conceptual background and architecture\n- DUPLICATE: Redundant content to archive\n- OUTDATED: Content needing updates\"\n```\n\n#### Directory Structure\nModify the target directories in the \"Structure Migration Plan\" node:\n\n```javascript\n// Custom directory mapping\nswitch (category) {\n  case 'TUTORIAL':\n    targetDir = 'docs/learn/';\n    break;\n  case 'HOW_TO':\n    targetDir = 'docs/guides/';\n    break;\n  // ... customize as needed\n}\n```\n\n#### File Processing Rules\nAdjust file filtering in \"Process & Prepare Files\":\n\n```javascript\n// Custom file filtering\nif (fileName.includes('TEMP') || fileName.includes('OLD')) {\n  priority = 'archive';\n}\nif (fileName.includes('API') || fileName.includes('SCHEMA')) {\n  priority = 'critical';\n}\n```\n\n## 📊 Workflow Outputs\n\n### Generated Reports\n1. **Cleanup Report**: `docs/reports/DOCUMENTATION_CLEANUP_REPORT_YYYY-MM-DD.md`\n2. **Migration Log**: `docs/archive/migration-logs/MIGRATION_LOG_YYYY-MM-DD_HH-MM-SS.json`\n3. **Updated README**: Root `README.md` with new structure\n\n### New Directory Structure\n```\ndocs/\n├── MASTER_DOCUMENTATION_INDEX.md\n├── tutorials/\n│   ├── getting-started/\n│   ├── study-creation/\n│   └── ai-features/\n├── how-to-guides/\n│   ├── installation/\n│   ├── deployment/\n│   └── troubleshooting/\n├── reference/\n│   ├── api/\n│   ├── database-schema/\n│   └── configuration/\n├── explanation/\n│   ├── architecture/\n│   └── design-decisions/\n├── requirements/ (preserved)\n├── reports/\n└── archive/\n    ├── old-docs/\n    └── migration-logs/\n```\n\n## 🎯 Usage Instructions\n\n### Running the Workflow\n\n1. **Manual Execution**:\n   - Click \"Test workflow\" in n8n\n   - Monitor progress through each node\n   - Review results in the execution log\n\n2. **Scheduled Execution**:\n   - Add a Schedule Trigger node\n   - Set to run weekly for ongoing maintenance\n\n3. **Webhook Trigger**:\n   - Use the webhook for external triggers\n   - Integrate with GitHub Actions or CI/CD\n\n### Monitoring Results\n\n1. **Check Execution Logs**:\n   - Review each node's output\n   - Verify file categorization accuracy\n   - Monitor any errors or failures\n\n2. **Validate Migration**:\n   - Check migrated files in new locations\n   - Verify metadata headers were added\n   - Review file content preservation\n\n3. **Review Reports**:\n   - Read the generated cleanup report\n   - Check migration statistics\n   - Validate recommendations\n\n## 🔄 Post-Migration Steps\n\n### 1. Manual Review\n- Review AI categorization decisions\n- Adjust any misclassified files\n- Update file content as needed\n\n### 2. Update Internal Links\n- Search for broken internal links\n- Update references to moved files\n- Test all documentation links\n\n### 3. Create Missing Documentation\n- Fill in placeholder files\n- Create essential how-to guides\n- Write missing reference documentation\n\n### 4. Setup Maintenance\n- Configure periodic documentation audits\n- Establish content review processes\n- Train team on new structure\n\n## 🎉 Expected Benefits\n\n### Immediate Improvements\n✅ **Organized Structure**: Clear categorization using Diátaxis framework\n✅ **Better Discoverability**: Users can find information based on their needs\n✅ **Reduced Duplication**: Duplicate content identified and archived\n✅ **Quality Standards**: Consistent documentation format and structure\n\n### Long-term Benefits\n✅ **Maintainability**: Easier to keep documentation current\n✅ **Scalability**: Clear framework for adding new documentation\n✅ **User Experience**: Faster information discovery and learning\n✅ **Team Efficiency**: Reduced time spent searching for information\n\n## 🆘 Troubleshooting\n\n### Common Issues\n\n1. **File Access Errors**:\n   - Verify n8n has file system permissions\n   - Check file paths are correct\n   - Ensure no files are locked/in use\n\n2. **AI API Errors**:\n   - Validate OpenAI API key\n   - Check rate limits and quotas\n   - Monitor token usage\n\n3. **Large File Processing**:\n   - Split large files into smaller chunks\n   - Increase workflow timeout settings\n   - Process files in batches\n\n4. **Memory Issues**:\n   - Reduce concurrent file processing\n   - Clear workflow data between runs\n   - Optimize file content analysis\n\n### Getting Help\n\n- **n8n Documentation**: [https://docs.n8n.io](https://docs.n8n.io)\n- **OpenAI API Docs**: [https://platform.openai.com/docs](https://platform.openai.com/docs)\n- **Diátaxis Framework**: [https://diataxis.fr](https://diataxis.fr)\n\n---\n\n*This workflow represents a complete automation solution for documentation restructuring using modern AI and workflow automation tools.*
